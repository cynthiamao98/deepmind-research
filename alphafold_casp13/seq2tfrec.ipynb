{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/SXMao/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import os\n",
    "\n",
    "import cProfile\n",
    "from contacts_dataset import *\n",
    "import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tf.enable_eager_execution()\n",
    "\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "\n",
    "features = [\n",
    "      \"profile\",\n",
    "      \"hhblits_profile\",\n",
    "      \"aatype\",\n",
    "#       \"pseudo_frob\",\n",
    "#       \"pseudolikelihood\",\n",
    "#       \"deletion_probability\",\n",
    "#       \"gap_matrix\",\n",
    "#       \"pseudo_bias\",\n",
    "#       \"profile_with_prior\",\n",
    "#       \"profile_with_prior_without_gaps\",\n",
    "#       \"reweighted_profile\",\n",
    "#       \"non_gapped_profile\",\n",
    "#       \"hmm_profile\",\n",
    "#       \"num_alignments\",\n",
    "      \"seq_length\",\n",
    "#       \"num_effective_alignments\",\n",
    "#       \"resolution\",\n",
    "#       \"sec_structure\",\n",
    "#       \"sec_structure_mask\",\n",
    "#       \"solv_surf\",\n",
    "#       \"solv_surf_mask\",\n",
    "#       \"beta_positions\",\n",
    "#       \"beta_mask\",\n",
    "#       \"domain_name\",\n",
    "#       \"chain_name\",\n",
    "#       \"resolution\",\n",
    "#       \"num_alignments\",\n",
    "#       \"superfamily\",\n",
    "#       \"profile\",\n",
    "#       \"hhblits_profile\",\n",
    "#       \"residue_index\",\n",
    "#       \"between_segment_residues\",\n",
    "#       \"sequence\"\n",
    "    ]\n",
    "\n",
    "needed_features = [\n",
    "    'aatype',\n",
    "    'deletion_probability',\n",
    "    'gap_matrix',\n",
    "    'hmm_profile',\n",
    "#     'mutual_information',\n",
    "    'non_gapped_profile',\n",
    "    'num_alignments',\n",
    "    'profile_with_prior',\n",
    "    'profile_with_prior_without_gaps',\n",
    "    'pseudo_bias',\n",
    "    'pseudo_frob',\n",
    "    'pseudolikelihood',\n",
    "    'residue_index',\n",
    "    'reweighted_profile',\n",
    "    'seq_length',\n",
    "    'sequence'\n",
    "] #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = {\n",
    "    'aatype': (tf.float32, [NUM_RES, 21]),\n",
    "    'alpha_mask': (tf.int64, [NUM_RES, 1]),\n",
    "    'alpha_positions': (tf.float32, [NUM_RES, 3]),\n",
    "    'beta_mask': (tf.int64, [NUM_RES, 1]),\n",
    "    'beta_positions': (tf.float32, [NUM_RES, 3]),\n",
    "    'between_segment_residues': (tf.int64, [NUM_RES, 1]),\n",
    "    'chain_name': (tf.string, [1]),\n",
    "    'deletion_probability': (tf.float32, [NUM_RES, 1]),\n",
    "    'domain_name': (tf.string, [1]),\n",
    "    'gap_matrix': (tf.float32, [NUM_RES, NUM_RES, 1]),\n",
    "    'hhblits_profile': (tf.float32, [NUM_RES, 22]),\n",
    "    'hmm_profile': (tf.float32, [NUM_RES, 30]),\n",
    "#     'key': (tf.string, [1]),\n",
    "    'mutual_information': (tf.float32, [NUM_RES, NUM_RES, 1]),\n",
    "    'non_gapped_profile': (tf.float32, [NUM_RES, 21]),\n",
    "    'num_alignments': (tf.int64, [NUM_RES, 1]),\n",
    "    'num_effective_alignments': (tf.float32, [1]),\n",
    "    'phi_angles': (tf.float32, [NUM_RES, 1]),\n",
    "    'phi_mask': (tf.int64, [NUM_RES, 1]),\n",
    "    'profile': (tf.float32, [NUM_RES, 21]),\n",
    "    'profile_with_prior': (tf.float32, [NUM_RES, 22]),\n",
    "    'profile_with_prior_without_gaps': (tf.float32, [NUM_RES, 21]),\n",
    "    'pseudo_bias': (tf.float32, [NUM_RES, 22]),\n",
    "    'pseudo_frob': (tf.float32, [NUM_RES, NUM_RES, 1]),\n",
    "    'pseudolikelihood': (tf.float32, [NUM_RES, NUM_RES, 484]),\n",
    "    'psi_angles': (tf.float32, [NUM_RES, 1]),\n",
    "    'psi_mask': (tf.int64, [NUM_RES, 1]),\n",
    "    'residue_index': (tf.int64, [NUM_RES, 1]),\n",
    "    'resolution': (tf.float32, [1]),\n",
    "    'reweighted_profile': (tf.float32, [NUM_RES, 22]),\n",
    "    'sec_structure': (tf.int64, [NUM_RES, 8]),\n",
    "    'sec_structure_mask': (tf.int64, [NUM_RES, 1]),\n",
    "    'seq_length': (tf.int64, [NUM_RES, 1]),\n",
    "    'sequence': (tf.string, [1]),\n",
    "    'solv_surf': (tf.float32, [NUM_RES, 1]),\n",
    "    'solv_surf_mask': (tf.int64, [NUM_RES, 1]),\n",
    "    'superfamily': (tf.string, [1]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(data, features=features):\n",
    "    feature_map = {}\n",
    "    for f in features:\n",
    "        print(f)\n",
    "        if FEATURES.get(f)[0] == tf.float32:\n",
    "#             print('float32')\n",
    "            feature_map[f] = _float_feature(data[f].numpy())\n",
    "        elif FEATURES.get(f)[0] == tf.int64:\n",
    "#             print('int64')\n",
    "            feature_map[f] = _int64_feature(data[f].numpy())\n",
    "        elif FEATURES.get(f)[0] == tf.string:\n",
    "#             print('string')\n",
    "            feature_map[f] = _bytes_feature(data[f])\n",
    "#         print(feature_map)\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_map))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aatype',\n",
       " 'alpha_mask',\n",
       " 'alpha_positions',\n",
       " 'beta_mask',\n",
       " 'beta_positions',\n",
       " 'between_segment_residues',\n",
       " 'chain_name',\n",
       " 'deletion_probability',\n",
       " 'domain_name',\n",
       " 'gap_matrix',\n",
       " 'hhblits_profile',\n",
       " 'hmm_profile',\n",
       " 'mutual_information',\n",
       " 'non_gapped_profile',\n",
       " 'num_alignments',\n",
       " 'num_effective_alignments',\n",
       " 'phi_angles',\n",
       " 'phi_mask',\n",
       " 'profile',\n",
       " 'profile_with_prior',\n",
       " 'profile_with_prior_without_gaps',\n",
       " 'pseudo_bias',\n",
       " 'pseudo_frob',\n",
       " 'pseudolikelihood',\n",
       " 'psi_angles',\n",
       " 'psi_mask',\n",
       " 'residue_index',\n",
       " 'resolution',\n",
       " 'reweighted_profile',\n",
       " 'sec_structure',\n",
       " 'sec_structure_mask',\n",
       " 'seq_length',\n",
       " 'sequence',\n",
       " 'solv_surf',\n",
       " 'solv_surf_mask',\n",
       " 'superfamily']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(FEATURES.keys())\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aatype',\n",
       " 'alpha_mask',\n",
       " 'alpha_positions',\n",
       " 'beta_mask',\n",
       " 'beta_positions',\n",
       " 'between_segment_residues',\n",
       " 'chain_name',\n",
       " 'deletion_probability',\n",
       " 'domain_name',\n",
       " 'gap_matrix',\n",
       " 'hhblits_profile',\n",
       " 'hmm_profile',\n",
       " 'mutual_information',\n",
       " 'non_gapped_profile',\n",
       " 'num_alignments',\n",
       " 'num_effective_alignments',\n",
       " 'phi_angles',\n",
       " 'phi_mask',\n",
       " 'profile',\n",
       " 'profile_with_prior',\n",
       " 'profile_with_prior_without_gaps',\n",
       " 'pseudo_bias',\n",
       " 'pseudo_frob',\n",
       " 'pseudolikelihood',\n",
       " 'psi_angles',\n",
       " 'psi_mask',\n",
       " 'residue_index',\n",
       " 'resolution',\n",
       " 'reweighted_profile',\n",
       " 'sec_structure',\n",
       " 'sec_structure_mask',\n",
       " 'seq_length',\n",
       " 'sequence',\n",
       " 'solv_surf',\n",
       " 'solv_surf_mask',\n",
       " 'superfamily']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = FEATURES.keys()\n",
    "tf_dataset = create_tf_dataset('./casp13_data/T0955/T0955.tfrec', features)\n",
    "# tf_dataset = tf.data.TFRecordDataset(filenames=['./casp13_data/T0965/T0965.tfrec'])\n",
    "# tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aatype\n",
      "alpha_mask\n",
      "alpha_positions\n",
      "beta_mask\n",
      "beta_positions\n",
      "between_segment_residues\n",
      "chain_name\n",
      "deletion_probability\n",
      "domain_name\n",
      "gap_matrix\n",
      "hhblits_profile\n",
      "hmm_profile\n",
      "mutual_information\n",
      "non_gapped_profile\n",
      "num_alignments\n",
      "num_effective_alignments\n",
      "phi_angles\n",
      "phi_mask\n",
      "profile\n",
      "profile_with_prior\n",
      "profile_with_prior_without_gaps\n",
      "pseudo_bias\n",
      "pseudo_frob\n",
      "pseudolikelihood\n",
      "psi_angles\n",
      "psi_mask\n",
      "residue_index\n",
      "resolution\n",
      "reweighted_profile\n",
      "sec_structure\n",
      "sec_structure_mask\n",
      "seq_length\n",
      "sequence\n",
      "solv_surf\n",
      "solv_surf_mask\n",
      "superfamily\n"
     ]
    }
   ],
   "source": [
    "new_examples = []\n",
    "for example in tf_dataset.take(10):\n",
    "    data = {}\n",
    "    for f in features:\n",
    "#         print('num_alignments', example['num_alignments'])\n",
    "        data[f] = tf.reshape(example[f], [-1])\n",
    "#         if f not in needed_features:\n",
    "#             data[f] = tf.zeros(data[f].shape, dtype=FEATURES.get(f)[0])\n",
    "#     print(data)\n",
    "    new_example = create_example(data, features=features)\n",
    "#     print(new_example)\n",
    "    new_examples.append(new_example)\n",
    "\n",
    "# new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aatype\n",
      "alpha_mask\n",
      "alpha_positions\n",
      "beta_mask\n",
      "beta_positions\n",
      "between_segment_residues\n",
      "chain_name\n",
      "deletion_probability\n",
      "domain_name\n",
      "gap_matrix\n",
      "hhblits_profile\n",
      "hmm_profile\n",
      "mutual_information\n",
      "non_gapped_profile\n",
      "num_alignments\n",
      "num_effective_alignments\n",
      "phi_angles\n",
      "phi_mask\n",
      "profile\n",
      "profile_with_prior\n",
      "profile_with_prior_without_gaps\n",
      "pseudo_bias\n",
      "pseudo_frob\n",
      "pseudolikelihood\n",
      "psi_angles\n",
      "psi_mask\n",
      "residue_index\n",
      "resolution\n",
      "reweighted_profile\n",
      "sec_structure\n",
      "sec_structure_mask\n",
      "seq_length\n",
      "sequence\n",
      "solv_surf\n",
      "solv_surf_mask\n",
      "superfamily\n"
     ]
    }
   ],
   "source": [
    "with tf.python_io.TFRecordWriter('./test/T0955/T0955.tfrec') as writer:\n",
    "    for example in tf_dataset.take(20):\n",
    "        data = {}\n",
    "        for f in features:\n",
    "            data[f] = tf.reshape(example[f], [-1])\n",
    "            if f not in ['chain_name', 'domain_name'] and f not in needed_features:\n",
    "                data[f] = tf.zeros(data[f].shape, dtype=FEATURES.get(f)[0])\n",
    "#         print(data)\n",
    "        new_example = create_example(data, features=features)\n",
    "        writer.write(new_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_tf_dataset('./test/T0955/T0955.tfrec', list(FEATURES.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "for example in test_dataset.take(1):\n",
    "    data = {}\n",
    "    for f in features:\n",
    "        data[f] = example[f]\n",
    "    print(len(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aatype', 'alpha_mask', 'alpha_positions', 'beta_mask', 'beta_positions', 'between_segment_residues', 'chain_name', 'deletion_probability', 'domain_name', 'gap_matrix', 'hhblits_profile', 'hmm_profile', 'mutual_information', 'non_gapped_profile', 'num_alignments', 'num_effective_alignments', 'phi_angles', 'phi_mask', 'profile', 'profile_with_prior', 'profile_with_prior_without_gaps', 'pseudo_bias', 'pseudo_frob', 'pseudolikelihood', 'psi_angles', 'psi_mask', 'residue_index', 'resolution', 'reweighted_profile', 'sec_structure', 'sec_structure_mask', 'seq_length', 'sequence', 'solv_surf', 'solv_surf_mask', 'superfamily']\n"
     ]
    }
   ],
   "source": [
    "for example in tf_dataset.take(1):\n",
    "    true_data = {}\n",
    "    for f in features:\n",
    "        true_data[f] = example[f]\n",
    "    print(list(true_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhblits_profile\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(41, 22), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(41, 22), dtype=float32)\n",
      "num_effective_alignments\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "phi_mask\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]], shape=(41, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]], shape=(41, 1), dtype=int64)\n",
      "profile\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(41, 21), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1. -1.  0.  0. -2.  0. -1. -2.  0. -2. -1.  1. -1.  0. -1.  4.  1. -2.\n",
      "  -3.  0. -2.]\n",
      " [-1. -3.  0.  2. -3. -2.  0. -3.  1. -2.  0.  0. -1.  5.  1.  0. -1. -2.\n",
      "  -2. -1. -1.]\n",
      " [-1. -4.  2.  5. -3. -2.  0. -3.  1. -3. -2.  0. -1.  2.  0.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [ 0. -1. -1. -1. -2. -2. -2. -1. -1. -1. -1.  0. -1. -1. -1.  1.  5.  0.\n",
      "  -2.  0. -2.]\n",
      " [-1. -3. -2.  0. -3. -2.  0. -3.  2. -2. -1.  0. -2.  1.  5. -1. -1. -3.\n",
      "  -3. -1. -2.]\n",
      " [-1. -3. -1.  1. -3. -2. -1. -3.  5. -2. -1.  0. -1.  1.  2.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [-1. -3. -1.  1. -3. -2. -1. -3.  5. -2. -1.  0. -1.  1.  2.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [ 0. 10. -3. -4. -2. -3. -3. -1. -3. -1. -1. -3. -3. -3. -3. -1. -1. -1.\n",
      "  -2. -2. -2.]\n",
      " [ 0. -1. -1. -1. -2. -2. -2. -1. -1. -1. -1.  0. -1. -1. -1.  1.  5.  0.\n",
      "  -2.  0. -2.]\n",
      " [-1. -4.  2.  5. -3. -2.  0. -3.  1. -3. -2.  0. -1.  2.  0.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [-1. -1. -3. -2.  0. -3. -2.  1. -1.  2.  5. -2. -2.  0. -1. -1. -1.  1.\n",
      "  -1. -1. -1.]\n",
      " [-1. -3. -1.  1. -3. -2. -1. -3.  5. -2. -1.  0. -1.  1.  2.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [-1. -3. -1.  1. -3. -2. -1. -3.  5. -2. -1.  0. -1.  1.  2.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [-1. -3. -1.  1. -3. -2. -1. -3.  5. -2. -1.  0. -1.  1.  2.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [-2. -2. -3. -3.  6. -3. -1.  0. -3.  0.  0. -3. -4. -3. -3. -2. -2. -1.\n",
      "   1. -1.  3.]\n",
      " [-1. -3. -1.  1. -3. -2. -1. -3.  5. -2. -1.  0. -1.  1.  2.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [-2. -3.  1.  0. -3.  0.  1. -3.  0. -3. -2.  6. -2.  0.  0.  1.  0. -3.\n",
      "  -4. -1. -2.]\n",
      " [ 0. 10. -3. -4. -2. -3. -3. -1. -3. -1. -1. -3. -3. -3. -3. -1. -1. -1.\n",
      "  -2. -2. -2.]\n",
      " [-1. -4.  2.  5. -3. -2.  0. -3.  1. -3. -2.  0. -1.  2.  0.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [ 0. -1. -3. -2. -1. -3. -3.  3. -2.  1.  1. -3. -2. -2. -3. -2.  0.  4.\n",
      "  -3. -1. -1.]\n",
      " [-1. -3. -2.  0. -3. -2.  0. -3.  2. -2. -1.  0. -2.  1.  5. -1. -1. -3.\n",
      "  -3. -1. -2.]\n",
      " [ 0. 10. -3. -4. -2. -3. -3. -1. -3. -1. -1. -3. -3. -3. -3. -1. -1. -1.\n",
      "  -2. -2. -2.]\n",
      " [-2. -3.  6.  2. -3. -1. -1. -3. -1. -4. -3.  1. -1.  0. -2.  0. -1. -3.\n",
      "  -4. -1. -3.]\n",
      " [-1. -4.  2.  5. -3. -2.  0. -3.  1. -3. -2.  0. -1.  2.  0.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [ 1. -1.  0.  0. -2.  0. -1. -2.  0. -2. -1.  1. -1.  0. -1.  4.  1. -2.\n",
      "  -3.  0. -2.]\n",
      " [-2. -3.  1.  0. -3.  0.  1. -3.  0. -3. -2.  6. -2.  0.  0.  1.  0. -3.\n",
      "  -4. -1. -2.]\n",
      " [-2. -3. -1.  0. -1. -2.  8. -3. -1. -3. -2.  1. -2.  0.  0. -1. -2. -3.\n",
      "  -2. -1.  2.]\n",
      " [ 0. 10. -3. -4. -2. -3. -3. -1. -3. -1. -1. -3. -3. -3. -3. -1. -1. -1.\n",
      "  -2. -2. -2.]\n",
      " [ 0. -1. -3. -2. -1. -3. -3.  3. -2.  1.  1. -3. -2. -2. -3. -2.  0.  4.\n",
      "  -3. -1. -1.]\n",
      " [-1. -4.  2.  5. -3. -2.  0. -3.  1. -3. -2.  0. -1.  2.  0.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [ 0. -1. -3. -2. -1. -3. -3.  3. -2.  1.  1. -3. -2. -2. -3. -2.  0.  4.\n",
      "  -3. -1. -1.]\n",
      " [-1. -3. -2.  0. -3. -2.  0. -3.  2. -2. -1.  0. -2.  1.  5. -1. -1. -3.\n",
      "  -3. -1. -2.]\n",
      " [ 0. 10. -3. -4. -2. -3. -3. -1. -3. -1. -1. -3. -3. -3. -3. -1. -1. -1.\n",
      "  -2. -2. -2.]\n",
      " [ 1. -1.  0.  0. -2.  0. -1. -2.  0. -2. -1.  1. -1.  0. -1.  4.  1. -2.\n",
      "  -3.  0. -2.]\n",
      " [-2. -3.  6.  2. -3. -1. -1. -3. -1. -4. -3.  1. -1.  0. -2.  0. -1. -3.\n",
      "  -4. -1. -3.]\n",
      " [ 0. -1. -1. -1. -2. -2. -2. -1. -1. -1. -1.  0. -1. -1. -1.  1.  5.  0.\n",
      "  -2.  0. -2.]\n",
      " [-1. -3. -1.  1. -3. -2. -1. -3.  5. -2. -1.  0. -1.  1.  2.  0. -1. -2.\n",
      "  -3. -1. -2.]\n",
      " [-2. -2. -3. -2.  3. -3.  2. -1. -2. -1. -1. -2. -3. -1. -2. -2. -2. -1.\n",
      "   2. -1.  7.]\n",
      " [ 0. -1. -1. -1. -2. -2. -2. -1. -1. -1. -1.  0. -1. -1. -1.  1.  5.  0.\n",
      "  -2.  0. -2.]\n",
      " [-1. -1. -4. -3.  0. -4. -3.  2. -2.  4.  2. -3. -3. -2. -2. -2. -1.  1.\n",
      "  -2. -1. -1.]\n",
      " [ 0. 10. -3. -4. -2. -3. -3. -1. -3. -1. -1. -3. -3. -3. -3. -1. -1. -1.\n",
      "  -2. -2. -2.]], shape=(41, 21), dtype=float32)\n",
      "psi_mask\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]], shape=(41, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]], shape=(41, 1), dtype=int64)\n",
      "sec_structure\n",
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]], shape=(41, 8), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]], shape=(41, 8), dtype=int64)\n",
      "sec_structure_mask\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]], shape=(41, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]], shape=(41, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for f in features:\n",
    "#     print(f)\n",
    "    if not np.array_equal(data[f].numpy(), true_data[f].numpy()):\n",
    "        print(f)\n",
    "        print(data[f])\n",
    "        print(true_data[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=24167, shape=(41, 30), dtype=float32, numpy=\n",
       "array([[0. , 0. , 0. , ..., 0.5, 1. , 1. ],\n",
       "       [0. , 0. , 0. , ..., 0.5, 1. , 1. ],\n",
       "       [0. , 0. , 0. , ..., 0.5, 1. , 1. ],\n",
       "       ...,\n",
       "       [0. , 0. , 0. , ..., 0.5, 1. , 1. ],\n",
       "       [0. , 0. , 0. , ..., 0.5, 1. , 1. ],\n",
       "       [0. , 1. , 0. , ..., 0.5, 1. , 1. ]], dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_data['hmm_profile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
